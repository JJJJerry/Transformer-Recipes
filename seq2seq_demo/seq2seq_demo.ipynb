{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立Dataloader\n",
    "max_ids=24\n",
    "embed_dim=64\n",
    "index_pad=0\n",
    "index_bos=1\n",
    "index_eos=2\n",
    "\n",
    "def make_dataset(data_num):\n",
    "    dataset=[]\n",
    "    def myiter(start,max):\n",
    "        while start <=max:\n",
    "            yield start\n",
    "            start+=2\n",
    "    \n",
    "    for _ in range(data_num):\n",
    "        x_start=random.randint(3,6)\n",
    "        x_stop=x_start+random.randint(1,3)*2\n",
    "        x_ids=torch.tensor([index_bos]+list(range(x_start,x_stop,2))+[index_eos])\n",
    "        y_start=x_stop\n",
    "        y_ids=torch.tensor([index_bos]+[i for i in myiter(y_start,max_ids-1)]+[index_eos])\n",
    "        dataset.append(\n",
    "            {\n",
    "                'x_ids':x_ids,\n",
    "                'y_ids':y_ids\n",
    "            }\n",
    "        )\n",
    "    def collate_fn(batch):\n",
    "        x_ids=[b['x_ids'] for b in batch]\n",
    "        y_ids=[b['y_ids'] for b in batch]\n",
    "        x_ids=nn.utils.rnn.pad_sequence(x_ids,padding_value=index_pad)\n",
    "        y_ids=nn.utils.rnn.pad_sequence(y_ids,padding_value=index_pad) # (seq_len,batch_size)\n",
    "        \n",
    "        batch={\n",
    "                'x_ids':x_ids,\n",
    "                'y_ids':y_ids\n",
    "            }\n",
    "        return batch\n",
    "    return dataset,collate_fn\n",
    "train_dataset,collate_fn=make_dataset(data_num=10000) # 构造一个y=x+1的序列\n",
    "batch_size=16\n",
    "train_dataloader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_ids': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "         [ 4,  5,  5,  5,  6,  5,  5,  5,  6,  4,  3,  6,  6,  6,  5,  4],\n",
       "         [ 6,  2,  7,  7,  8,  7,  7,  7,  8,  6,  2,  2,  8,  2,  7,  2],\n",
       "         [ 8,  0,  9,  2, 10,  2,  2,  2,  2,  8,  0,  0, 10,  0,  9,  0],\n",
       "         [ 2,  0,  2,  0,  2,  0,  0,  0,  0,  2,  0,  0,  2,  0,  2,  0]]),\n",
       " 'y_ids': tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "         [10,  7, 11,  9, 12,  9,  9,  9, 10, 10,  5,  8, 12,  8, 11,  6],\n",
       "         [12,  9, 13, 11, 14, 11, 11, 11, 12, 12,  7, 10, 14, 10, 13,  8],\n",
       "         [14, 11, 15, 13, 16, 13, 13, 13, 14, 14,  9, 12, 16, 12, 15, 10],\n",
       "         [16, 13, 17, 15, 18, 15, 15, 15, 16, 16, 11, 14, 18, 14, 17, 12],\n",
       "         [18, 15, 19, 17, 20, 17, 17, 17, 18, 18, 13, 16, 20, 16, 19, 14],\n",
       "         [20, 17, 21, 19, 22, 19, 19, 19, 20, 20, 15, 18, 22, 18, 21, 16],\n",
       "         [22, 19, 23, 21,  2, 21, 21, 21, 22, 22, 17, 20,  2, 20, 23, 18],\n",
       "         [ 2, 21,  2, 23,  0, 23, 23, 23,  2,  2, 19, 22,  0, 22,  2, 20],\n",
       "         [ 0, 23,  0,  2,  0,  2,  2,  2,  0,  0, 21,  2,  0,  2,  0, 22],\n",
       "         [ 0,  2,  0,  0,  0,  0,  0,  0,  0,  0, 23,  0,  0,  0,  0,  2],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dataloader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,max_ids,embed_dim,hidden_dim,num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding=nn.Embedding(num_embeddings=max_ids,embedding_dim=embed_dim)\n",
    "        self.lstm=nn.LSTM(input_size=embed_dim,hidden_size=hidden_dim,num_layers=num_layers)\n",
    "    def forward(self,input_ids):\n",
    "        x=self.embedding(input_ids) # (seq_len,batch_size,hidden_dim)\n",
    "        lstm_output,(hidden_states,cell)=self.lstm(x) # (seq_len,batch_size,hidden_dim)\n",
    "        return hidden_states,cell # (num_layers,batch_size,hidden_dim)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,max_ids,embed_dim,hidden_dim,num_layers):\n",
    "        super().__init__()\n",
    "        self.lstm=nn.LSTM(input_size=embed_dim,hidden_size=hidden_dim,num_layers=num_layers)\n",
    "        self.embedding=nn.Embedding(num_embeddings=max_ids,embedding_dim=embed_dim)\n",
    "        self.head=nn.Linear(hidden_dim,max_ids)\n",
    "    def forward(self,input_ids,hidden_states,cell):\n",
    "        # input_ids:(seq_len,batch_size)\n",
    "        x=self.embedding(input_ids)\n",
    "        lstm_output,(hidden_states,cell)=self.lstm(x,(hidden_states,cell)) # (seq_len,batch_size,hidden_dim)\n",
    "        output=self.head(lstm_output) #(seq_len,batch_size,max_ids)\n",
    "        return output,(hidden_states,cell) \n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,max_ids,embed_dim,hidden_dim,num_layers,teacher_ratio):\n",
    "        super().__init__()\n",
    "        self.teacher_ratio=teacher_ratio\n",
    "        self.encoder=Encoder(max_ids=max_ids,embed_dim=embed_dim,hidden_dim=hidden_dim,num_layers=num_layers)\n",
    "        self.decoder=Decoder(max_ids=max_ids,embed_dim=embed_dim,hidden_dim=hidden_dim,num_layers=num_layers)\n",
    "    def forward(self,input_ids,tgt_ids):\n",
    "        # input_ids:(seq_len,batch_size)\n",
    "        # tgt_ids:(seq_len,batch_size)\n",
    "        hidden_states,cell=self.encoder(input_ids)\n",
    "        last_output_ids=tgt_ids[0,:].unsqueeze(0) # Decoder起始输入的都是第一个token\n",
    "        tgt_seq_len=tgt_ids.shape[0]\n",
    "        output=[]\n",
    "        for i in range(1,tgt_seq_len):\n",
    "            #print(last_output_ids.shape)\n",
    "            logits,(hidden_states,cell)=self.decoder(last_output_ids,hidden_states,cell)\n",
    "            output.append(logits.squeeze(0))\n",
    "            if random.random() < self.teacher_ratio:\n",
    "                last_output_ids=tgt_ids[i].unsqueeze(0) # teacher forcing\n",
    "            else :\n",
    "                last_output_ids=torch.argmax(logits,dim=-1)\n",
    "        return torch.stack(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 625/625 [00:14<00:00, 42.04it/s, loss=0.0015] \n",
      "Epoch 2/3: 100%|██████████| 625/625 [00:14<00:00, 44.43it/s, loss=0.000598]\n",
      "Epoch 3/3: 100%|██████████| 625/625 [00:14<00:00, 44.60it/s, loss=0.000362]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "    \n",
    "hidden_dim=128\n",
    "num_layers=3\n",
    "device='cuda:0'\n",
    "teacher_ratio=0.5\n",
    "model=Seq2Seq(max_ids=max_ids,embed_dim=embed_dim,hidden_dim=hidden_dim,num_layers=num_layers,teacher_ratio=teacher_ratio).to(device)\n",
    "model.train()\n",
    "loss_func=nn.CrossEntropyLoss(ignore_index=index_pad) # 其实不ignore也行，因为tgt中的padding token一定在eos后\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "epoch=3\n",
    "\n",
    "for i in range(epoch):\n",
    "    with tqdm(total=len(train_dataloader), desc=f\"Epoch {i+1}/{epoch}\") as pbar:\n",
    "        for batch in train_dataloader:\n",
    "            x_ids=batch['x_ids'].to(device) # (src_seq_len,batch_size)\n",
    "            y_ids=batch['y_ids'].to(device) # (tgt_seq_len,batch_size)\n",
    "            y_output=model(x_ids,y_ids) # (tgt_seq_len-1,batch_size)\n",
    "            y_ids=y_ids[1:] # (tgt_seq_len-1,batch_size) \n",
    "            y_output=y_output.view(-1,y_output.shape[-1])\n",
    "            y_ids=y_ids.view(-1)\n",
    "            loss=loss_func(y_output,y_ids)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({\"loss\": loss.item()/batch_size})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6, 8, 10, 12, 14, 16, 18, 20, 22, 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 pad,1 bos ,2 eos\n",
    "model.eval()\n",
    "encoder_input_ids= [index_bos]+[2,4]+[index_eos]\n",
    "input_ids=[torch.tensor(encoder_input_ids).to(device)]\n",
    "padded_input_ids=nn.utils.rnn.pad_sequence(input_ids,padding_value=index_pad)\n",
    "\n",
    "hidden_states,cell=model.encoder(padded_input_ids)\n",
    "\n",
    "\n",
    "res_ids=[]\n",
    "res_ids.append(index_bos)\n",
    "decoder_input_ids=[index_bos]\n",
    "max_len=16\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(max_len):\n",
    "        decoder_input_tensor=torch.LongTensor([decoder_input_ids[-1]]).to(device).unsqueeze(0)\n",
    "        output,(hidden_states,cell)=model.decoder(decoder_input_tensor,hidden_states,cell)\n",
    "        \n",
    "        output_id = torch.argmax(output,dim=2).item() # dim=-1\n",
    "        decoder_input_ids.append(output_id)  \n",
    "        if output_id==index_eos:\n",
    "            break\n",
    "decoder_input_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
