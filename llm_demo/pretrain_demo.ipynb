{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 设置hf-mirror镜像站，用于下载Qwen/Qwen2.5-0.5B模型\n",
    "import os\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "if config.pad_token_id is None:\n",
    "    config.pad_token_id = (\n",
    "        config.eos_token_id\n",
    "    )  # 避免提示：Setting pad_token_id to eos_token_id:None for open-end generation.\n",
    "model = AutoModelForCausalLM.from_config(config=config).to(device)  # 用from_config方法\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Config {\n",
       "  \"_name_or_path\": \"Qwen/Qwen2.5-0.5B\",\n",
       "  \"architectures\": [\n",
       "    \"Qwen2ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 151643,\n",
       "  \"eos_token_id\": 151643,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 896,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4864,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"max_window_layers\": 24,\n",
       "  \"model_type\": \"qwen2\",\n",
       "  \"num_attention_heads\": 14,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"pad_token_id\": 151643,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": null,\n",
       "  \"tie_word_embeddings\": true,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.46.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_mrope\": false,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"vocab_size\": 151936\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896, padding_idx=151643)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Config {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"Qwen/Qwen2.5-0.5B\",\n",
       "  \"architectures\": [\n",
       "    \"Qwen2ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 151643,\n",
       "  \"eos_token_id\": 151643,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 896,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4864,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"max_window_layers\": 24,\n",
       "  \"model_type\": \"qwen2\",\n",
       "  \"num_attention_heads\": 14,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"pad_token_id\": 151643,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": null,\n",
       "  \"tie_word_embeddings\": true,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.46.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_mrope\": false,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"vocab_size\": 151936\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 35946, 100644, 104753,  99165]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1]], device='cuda:0')}\n",
      "�� Wifi niche dalla dalla dalla Wifi Wifiレーション_readySansHoTypeError_ipHoHoHoḈḈ敦 chiến廓的那一幾個Ḉ敦影业影业影业影业疑问York skills\tinsert\tinsert\tinsert幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個幾個Binder$output$output$output$output\n"
     ]
    }
   ],
   "source": [
    "# 可以看出现在模型是一个完全初始化的状态\n",
    "prompt = \"我今天心情很\"\n",
    "model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n",
    "print(model_inputs)  # input_ids和attention_mask\n",
    "with torch.inference_mode():\n",
    "    model_output_ids = model.generate(**model_inputs, max_new_tokens=64)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, model_output_ids)\n",
    "]\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[[ 0.1496, -0.1355,  0.6572,  ...,  0.2197,  0.0963,  0.9431],\n",
      "         [-0.4937,  0.3464,  0.6783,  ..., -0.3669, -0.0607,  1.2321],\n",
      "         [-0.3737,  0.4515,  0.2831,  ..., -0.3511,  0.0225,  1.4325],\n",
      "         [ 0.0517,  0.3105, -0.0512,  ..., -0.5628, -0.4646,  1.2509]]],\n",
      "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 4, 151936])\n"
     ]
    }
   ],
   "source": [
    "model_forward_output = model.forward(**model_inputs)\n",
    "print(model_forward_output.loss)\n",
    "print(model_forward_output.logits)\n",
    "print(model_forward_output.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_jsonl\n",
    "\n",
    "data = load_jsonl(path=\"../data/webText2019zh_1k.jsonl\")\n",
    "train_texts = data[:900]\n",
    "eval_texts = data[900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx][\"text\"]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # 获取 input_ids 和 attention_mask\n",
    "        input_ids = encoding[\"input_ids\"].squeeze()  # 去掉批量维度\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "\n",
    "train_dataset = TextDataset(train_texts, tokenizer, max_length=512)\n",
    "eval_dataset = TextDataset(eval_texts, tokenizer, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([104719,  80268,  13343,  80268,  48692,  80268,  41406,   9370, 100714,\n",
      "         99800,  94432,  99729, 110878,   3837,  28291,  99601,  45629, 104511,\n",
      "         99425, 100228,  99894,  60726, 121292,  33447, 110798,  99486,  56006,\n",
      "        107514, 101494,  99898, 106678,   8997, 101895,  80268,  13343,  80268,\n",
      "         48692,  80268,  41406,   9370, 100714,  99800,  99519,  80443, 100386,\n",
      "        100162, 110596, 113757,   8997,  31207,  26232,   9370,  52183, 114615,\n",
      "          3837, 113717,  14880, 113145,  97084, 101893,  99800, 101454,   3837,\n",
      "         30709,  99952,  16530,  99813, 104305,   8997, 109619,  43268, 104305,\n",
      "         99466, 108845, 100651,   6313,    198, 101038,  99466,  99934, 105593,\n",
      "        105098, 100313,   9370, 102078,  99800,  99898,   3837,  99491, 103198,\n",
      "          3837, 112496, 121258, 100655,  52510, 103615, 112622, 109971,  77959,\n",
      "        101833, 121493, 104008,   3837, 104029, 101467, 116128,   8997,  28072,\n",
      "        105073,   9370, 113575,  20412,  99172,  99557,  99466, 101069,  99425,\n",
      "        100228,  99894,  18397, 101240,  99894,  79766, 101494, 100655,  99425,\n",
      "        100228, 100655,  49567, 100001,  38953,  99405,  99786, 105320, 103690,\n",
      "        100682,   9370,  99800, 106723,   8997, 112496,  18397, 101240,  99894,\n",
      "        109366,  20929, 100454, 102282,  36407, 101311,   3837,  11622,  99918,\n",
      "         85336, 106276,  99894,   9370, 116791,   8997, 103942,  92894, 105652,\n",
      "         99998, 106466, 105062,  60726, 104783,  33447, 103071,  87256, 101311,\n",
      "        106723,   8997,  99518, 101303,  79766, 101494, 100655,   3837, 107970,\n",
      "         36993, 101494,  20221, 105698, 105087, 102513, 102580,   3837, 103942,\n",
      "        111592,  49111,  49111,  42192,  99309,   8997, 104474,  99894, 101946,\n",
      "        100655, 111306, 102022, 114513, 100714, 100131, 103945, 101906,  33956,\n",
      "        100538, 106634, 105037,  99232, 107195,   8997, 101959,  20929,  34187,\n",
      "         80268,  13343,  80268,  48692,  80268,  41406,   9370,  24562, 103630,\n",
      "          8997,  99466, 109950, 118975,   3837, 107303, 102531,  36587, 102078,\n",
      "        100854,  52801,  99800,   8997, 104288, 105904,  99232,     17, 102874,\n",
      "         99360, 104474,  99219, 100428,  99338,  30767,   9370,  75108,  99232,\n",
      "         99894, 108453, 111306, 109843,  18397, 101240,  99894, 107523,  18830,\n",
      "         73670, 102881, 104140,   8997,  97706, 117997,  16530, 119321, 107059,\n",
      "         99182,   8997,  44636, 102022,    220, 102215,  15946,  99512,  99998,\n",
      "         60686,  99512,   9370,  44636, 102022, 100132,  99165,  80268,  13343,\n",
      "         80268,  48692,  99518,  80268,  41406,   9370,   3837, 101885,  99190,\n",
      "         99898, 104039, 101097, 100622, 104511,  99800, 102073, 104650,  11622,\n",
      "         41406,   8997,  35946,  99792, 114448, 115146, 101189,  33108, 102501,\n",
      "          9370, 111276, 100631,  24339,  28330,  44636, 102022,   3837, 109230,\n",
      "        115673,  34204,  33126, 116409,  99200,  17340, 100005, 107102,  36407,\n",
      "         54542,   3837,  24339,  28330,  44636, 102022, 106782,  15946, 106158,\n",
      "         99662,  41406,   3837, 111276,  44636, 102022, 104047,  11622,  24339,\n",
      "        106158, 118038,   1773, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643])\n",
      "有哪些费时费工费料的普通菜？\n",
      "喜欢做饭，发现在家一道红烧肉先煸后炖就是比饭店蒸出来好吃。\n",
      "有些费时费工费料的普通菜因为没有商业价值慢慢的消失了。\n",
      "万能的知友们，恳请传授些这样的菜谱，小弟不胜感谢。\n",
      "分割线感谢大家的热情参与！\n",
      "看到大家贴了一些很有意思的家里菜出来，非常感兴趣，譬如鲅鱼水饺香蕉土豆球茄鲞等等，让我开了眼界。\n",
      "提这个问题的初衷是想跟大家交流红烧肉回锅肉清蒸鱼红烧鱼等这些常吃却又有万千变化的菜的做法。\n",
      "譬如回锅肉我喜欢加泡姜来炒，用酸去化解肉的油腻。\n",
      "当然其他步骤还是遵循传统的先煮后熬再炒的做法。\n",
      "又想到清蒸鱼，偶然会蒸出让自己感动的好味道，当然更多的是平平无奇。\n",
      "一块肉一条鱼一碗汤貌似普通但是想要做好确实在各方面都很花心思。\n",
      "于是加了费时费工费料的前缀。\n",
      "大家若有兴致，不妨可以说说家里做的好菜。\n",
      "我觉得在家花2个小时把一块精挑细选的五花肉做成一碗精彩的回锅肉必定有可以讲述的事。\n",
      "还请大家不吝赐教。\n",
      "高汤 无论是中餐还是西餐的高汤都是很费时费工又费料的，而且做出来的东西只能作为一道菜里的辅助用料。\n",
      "我比较无所谓正宗工艺和做法的中式或者法式高汤，我还是偏向于更迎合各人自己的口味来处理，法式高汤可以用中式的香料，中式高汤也可以用法式的技法。<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0]['input_ids'])\n",
    "print(tokenizer.decode(train_dataset[0]['input_ids']))\n",
    "print(train_dataset[0]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size\n",
    ")\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=eval_dataset, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[104719,  80268,  13343,  ..., 151643, 151643, 151643],\n",
       "         [100007, 103964,     51,  ..., 151643, 151643, 151643],\n",
       "         [100344, 102073, 104467,  ..., 151643, 151643, 151643],\n",
       "         [118919,  99503, 100251,  ..., 151643, 151643, 151643]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dataloader.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, train_dataloader, loss_func, optimizer, device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    progress_bar = tqdm(train_dataloader, desc=\"Training\", total=len(train_dataloader))\n",
    "    for step,batch in enumerate(progress_bar):\n",
    "        inputs_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        text = inputs_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        text_input = text[:, :-1]  # 模型的输入是text的前n-1个token\n",
    "        logits = model.forward(\n",
    "            input_ids=text_input, attention_mask=attention_mask\n",
    "        ).logits\n",
    "        text_expected = text[:, 1:]  # 模型的期望输出是text的第2个token到第n个token\n",
    "        text_expected = text_expected.reshape(-1)\n",
    "        logits = logits.view(-1, logits.shape[-1])\n",
    "        loss = loss_func(logits, text_expected)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        progress_bar.set_postfix(loss=loss.item(), refresh=True)\n",
    "    return sum(losses) / (len(losses) * batch_size)\n",
    "\n",
    "\n",
    "@torch.inference_mode()  # 验证的时候关闭梯度计算\n",
    "def eval(model, eval_dataloader, loss_func, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    progress_bar = tqdm(eval_dataloader, desc=\"Evaluating\", total=len(eval_dataloader))\n",
    "    for step,batch in enumerate(progress_bar):\n",
    "        inputs_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        text = inputs_ids.to(device)\n",
    "        text_input = text[:, :-1]  # 模型的输入是text的前n-1个token\n",
    "        logits = model.forward(\n",
    "            input_ids=text_input, attention_mask=attention_mask\n",
    "        ).logits\n",
    "        text_expected = text[:, 1:]  # 模型的期望输出是text的第2个token到第n个token\n",
    "        text_expected = text_expected.reshape(-1)\n",
    "        logits = logits.view(-1, logits.shape[-1])\n",
    "        loss = loss_func(logits, text_expected)\n",
    "        progress_bar.set_postfix(loss=loss.item(), refresh=True)\n",
    "        losses.append(loss.item())\n",
    "    return sum(losses) / (len(losses) * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = torch.optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 225/225 [01:55<00:00,  1.94it/s, loss=8.1] \n",
      "Evaluating: 100%|██████████| 25/25 [00:04<00:00,  5.08it/s, loss=8.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, train_loss:2.1377231385972766, eval_loss:2.0396485424041746\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 225/225 [02:11<00:00,  1.72it/s, loss=7.38]\n",
      "Evaluating: 100%|██████████| 25/25 [00:05<00:00,  4.72it/s, loss=7.94]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, train_loss:1.8994581349690756, eval_loss:2.072402739524841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    train_loss = train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        loss_func=loss_func,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "    )\n",
    "    eval_loss = eval(\n",
    "        model=model, eval_dataloader=eval_dataloader, loss_func=loss_func, device=device\n",
    "    )\n",
    "    print(f\"Epoch:{epoch + 1}, train_loss:{train_loss}, eval_loss:{eval_loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
